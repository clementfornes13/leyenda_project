{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIVRABLE 1 - Classification binaire (Projet LEYENDA)\n",
    "\n",
    "# Objectif : Distinguer les photos naturelles (couleur ou noir et blanc) des autres types d'images (peintures, textes, dessins, sch√©mas...)\n",
    "\n",
    "CHANGER EN PNG, RESIZE\n",
    "MODELE RGB\n",
    "MODELE NB\n",
    "RECONNAITRE PHOTO PEINTURE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# üö© Partie 1 : Initialisation & V√©rification GPU\n",
    "# =======================\n",
    "\n",
    "# Importations g√©n√©rales\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ‚úÖ V√©rification de la disponibilit√© GPU (TensorFlow GPU Metal)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"[INFO] GPU d√©tect√© :\", gpus)\n",
    "else:\n",
    "    print(\"[WARNING] Pas de GPU d√©tect√©. V√©rifie tensorflow-metal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# üìÇ Partie 2 : Organisation initiale des dossiers\n",
    "# =======================\n",
    "\n",
    "# Chemins des dossiers\n",
    "source_dir = \"/Users/clementfornes/Downloads/leyenda project/images\"\n",
    "working_dir = \"/Users/clementfornes/Downloads/leyenda project/images_work\"\n",
    "\n",
    "# Auto-d√©tection des cat√©gories pr√©sentes dans source_dir\n",
    "categories = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n",
    "\n",
    "# Cr√©ation du dossier de travail et copie des images originales\n",
    "os.makedirs(working_dir, exist_ok=True)\n",
    "\n",
    "for category in categories:\n",
    "    src_path = os.path.join(source_dir, category)\n",
    "    dst_path = os.path.join(working_dir, category)\n",
    "\n",
    "    if not os.path.exists(dst_path):\n",
    "        shutil.copytree(src_path, dst_path)\n",
    "        print(f\"[COPIED] Cat√©gorie : {category}\")\n",
    "    else:\n",
    "        print(f\"[ALREADY EXISTS] Cat√©gorie : {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# üé® Partie 3 : Tri automatique en Couleur et Noir & Blanc\n",
    "# =======================\n",
    "\n",
    "# Dossier de travail et cat√©gories\n",
    "categories = [\"Painting\", \"Photo\", \"Schematics\", \"Sketch\", \"Text\"]\n",
    "\n",
    "# Fonction pour d√©tecter si une image est en niveau de gris\n",
    "def is_grayscale(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    np_img = np.array(img)\n",
    "    return np.all(np_img[:,:,0] == np_img[:,:,1]) and np.all(np_img[:,:,1] == np_img[:,:,2])\n",
    "\n",
    "# Tri des images selon la couleur\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category)\n",
    "\n",
    "    # Cr√©ation des sous-dossiers rgb et nb\n",
    "    rgb_path = os.path.join(path, \"rgb\")\n",
    "    nb_path = os.path.join(path, \"nb\")\n",
    "    os.makedirs(rgb_path, exist_ok=True)\n",
    "    os.makedirs(nb_path, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "    for file_name in tqdm(files, desc=f\"[CLASSIFY] {category}\", unit=\"image\"):\n",
    "        file_path = os.path.join(path, file_name)\n",
    "        base_name, ext = os.path.splitext(file_name)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(file_path).convert(\"RGB\")\n",
    "            np_img = np.array(img)\n",
    "\n",
    "            # V√©rifier si l'image est en noir et blanc ou couleur\n",
    "            dest_folder = nb_path if is_grayscale(file_path) else rgb_path\n",
    "\n",
    "            # Sauvegarde syst√©matique en PNG\n",
    "            new_filename = base_name + \".png\"\n",
    "            dest_path = os.path.join(dest_folder, new_filename)\n",
    "            img.save(dest_path, \"PNG\")\n",
    "\n",
    "            # Suppression des fichiers originaux non n√©cessaires\n",
    "            if os.path.abspath(dest_path) != os.path.abspath(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Fichier {file_path} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# üé® Partie 4 : Normalisation de la taille des images \n",
    "# =======================\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category)\n",
    "    resized_path = os.path.join(path, \"resized\", \"rgb\")\n",
    "    os.makedirs(resized_path, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(os.path.join(path, \"rgb\")) if os.path.isfile(os.path.join(path, \"rgb\", f))]\n",
    "    for file_name in tqdm(files, desc=f\"[RESIZE] {category}\", unit=\"image\"):\n",
    "        file_path = os.path.join(path, \"rgb\", file_name)\n",
    "        base_name, ext = os.path.splitext(file_name)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(file_path).convert(\"RGB\")\n",
    "            img_resized = img.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "            new_filename = base_name + \".png\"\n",
    "            dest_path = os.path.join(resized_path, new_filename)\n",
    "            img_resized.save(dest_path, \"PNG\")\n",
    "\n",
    "            # Suppression des fichiers originaux non n√©cessaires\n",
    "            if os.path.abspath(dest_path) != os.path.abspath(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Fichier {file_path} : {e}\")\n",
    "# Normalisation de la taille des images en noir et blanc\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category)\n",
    "    resized_path = os.path.join(path, \"resized\", \"nb\")\n",
    "    os.makedirs(resized_path, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(os.path.join(path, \"nb\")) if os.path.isfile(os.path.join(path, \"nb\", f))]\n",
    "    for file_name in tqdm(files, desc=f\"[RESIZE] {category}\", unit=\"image\"):\n",
    "        file_path = os.path.join(path, \"nb\", file_name)\n",
    "        base_name, ext = os.path.splitext(file_name)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(file_path).convert(\"RGB\")\n",
    "            img_resized = img.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "            new_filename = base_name + \".png\"\n",
    "            dest_path = os.path.join(resized_path, new_filename)\n",
    "            img_resized.save(dest_path, \"PNG\")\n",
    "\n",
    "            # Suppression des fichiers originaux non n√©cessaires\n",
    "            if os.path.abspath(dest_path) != os.path.abspath(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Fichier {file_path} : {e}\")\n",
    "# =======================\n",
    "print(\"[INFO] Tri et redimensionnement des images termin√©s.\")\n",
    "# Display des images tri√©es (nombre limit√© √† 12)\n",
    "def display_images_from_folder(folder_path):\n",
    "    images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.png')]\n",
    "    images = images[:12]  # Limiter √† 12 images\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, img_path in enumerate(images):\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "# Affichage des images tri√©es\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category, \"resized\", \"rgb\")\n",
    "    print(f\"[DISPLAY] Images de la cat√©gorie : {category}\")\n",
    "    display_images_from_folder(path)\n",
    "# =======================\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dossiers d'entra√Ænement et validation\n",
    "train_dir_rgb = os.path.join(working_dir, \"train\", \"rgb\")\n",
    "val_dir_rgb = os.path.join(working_dir, \"val\", \"rgb\")\n",
    "train_dir_nb = os.path.join(working_dir, \"train\", \"nb\")\n",
    "val_dir_nb = os.path.join(working_dir, \"val\", \"nb\")\n",
    "# Cr√©ation des dossiers d'entra√Ænement et validation\n",
    "os.makedirs(train_dir_rgb, exist_ok=True)\n",
    "os.makedirs(val_dir_rgb, exist_ok=True)\n",
    "os.makedirs(train_dir_nb, exist_ok=True)\n",
    "os.makedirs(val_dir_nb, exist_ok=True)\n",
    "# Cr√©ation des sous-dossiers pour chaque cat√©gorie\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(train_dir_rgb, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir_rgb, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(train_dir_nb, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir_nb, category), exist_ok=True)\n",
    "# Copie des images dans les dossiers d'entra√Ænement et validation\n",
    "# Copie des images RGB et NB (noir et blanc) dans les dossiers d'entra√Ænement et validation\n",
    "\n",
    "for category in categories:\n",
    "    # RGB\n",
    "    rgb_path = os.path.join(working_dir, category, \"resized\", \"rgb\")\n",
    "    files_rgb = [f for f in os.listdir(rgb_path) if f.endswith('.png')]\n",
    "    train_rgb, val_rgb = train_test_split(files_rgb, test_size=0.2, random_state=42)\n",
    "\n",
    "    for file_name in tqdm(train_rgb, desc=f\"[COPY TRAIN] {category} RGB\", unit=\"image\"):\n",
    "        src_path = os.path.join(rgb_path, file_name)\n",
    "        dst_path = os.path.join(train_dir_rgb, category, file_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "    for file_name in tqdm(val_rgb, desc=f\"[COPY VAL] {category} RGB\", unit=\"image\"):\n",
    "        src_path = os.path.join(rgb_path, file_name)\n",
    "        dst_path = os.path.join(val_dir_rgb, category, file_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "    # NB\n",
    "    nb_path = os.path.join(working_dir, category, \"resized\", \"nb\")\n",
    "    files_nb = [f for f in os.listdir(nb_path) if f.endswith('.png')]\n",
    "    train_nb, val_nb = train_test_split(files_nb, test_size=0.2, random_state=42)\n",
    "\n",
    "    for file_name in tqdm(train_nb, desc=f\"[COPY TRAIN] {category} NB\", unit=\"image\"):\n",
    "        src_path = os.path.join(nb_path, file_name)\n",
    "        dst_path = os.path.join(train_dir_nb, category, file_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "    for file_name in tqdm(val_nb, desc=f\"[COPY VAL] {category} NB\", unit=\"image\"):\n",
    "        src_path = os.path.join(nb_path, file_name)\n",
    "        dst_path = os.path.join(val_dir_nb, category, file_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "# =======================\n",
    "print(\"[INFO] Copie des images termin√©e.\")\n",
    "# =======================\n",
    "# Affichage des images tri√©es\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category, \"resized\", \"rgb\")\n",
    "    print(f\"[DISPLAY] Images de la cat√©gorie : {category}\")\n",
    "    display_images_from_folder(path)\n",
    "# =======================\n",
    "# Affichage des images tri√©es\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category, \"resized\", \"nb\")\n",
    "    print(f\"[DISPLAY] Images de la cat√©gorie : {category}\")\n",
    "    display_images_from_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# üì¶ Partie 5 : Chargement et Pr√©traitement des donn√©es\n",
    "# =======================\n",
    "\n",
    "# Chemins des dossiers d'entra√Ænement et de validation\n",
    "train_dir_rgb = os.path.join(working_dir, \"train\", \"rgb\")\n",
    "train_dir_nb = os.path.join(working_dir, \"train\", \"nb\")\n",
    "val_dir_rgb = os.path.join(working_dir, \"val\", \"rgb\")\n",
    "val_dir_nb = os.path.join(working_dir, \"val\", \"nb\")\n",
    "# Taille d'image cible\n",
    "img_height = 256    \n",
    "img_width = 256\n",
    "# Nombre de classes \n",
    "num_classes = len(categories) * 2  # RGB + NB\n",
    "# Chemin du dossier de sauvegarde des mod√®les\n",
    "model_dir = os.path.join(working_dir, \"models\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "# Chemin du dossier de sauvegarde des r√©sultats\n",
    "results_dir = os.path.join(working_dir, \"results\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "# Chemin du fichier de log\n",
    "log_file = os.path.join(results_dir, \"training_log.txt\")\n",
    "# Ouverture du fichier de log\n",
    "log = open(log_file, \"w\")\n",
    "# Fonction pour charger et pr√©traiter les images\n",
    "def load_and_preprocess_image(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img\n",
    "# Fonction pour charger les √©tiquettes\n",
    "def load_and_preprocess_label(label):\n",
    "    label = tf.strings.to_number(label, tf.int32)\n",
    "    return label\n",
    "# Fonction pour cr√©er un dataset √† partir d'un dossier\n",
    "def create_dataset_from_directory(directory, batch_size=32):\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    for label, category in enumerate(categories):\n",
    "        category_dir_rgb = os.path.join(directory, category)\n",
    "        category_dir_nb = os.path.join(directory, category)\n",
    "        for img_file in os.listdir(category_dir_rgb):\n",
    "            file_paths.append(os.path.join(category_dir_rgb, img_file))\n",
    "            labels.append(label)\n",
    "        for img_file in os.listdir(category_dir_nb):\n",
    "            file_paths.append(os.path.join(category_dir_nb, img_file))\n",
    "            labels.append(label + len(categories))  # D√©calage pour les images NB\n",
    "    file_paths = tf.convert_to_tensor(file_paths)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    dataset = dataset.map(lambda x, y: (load_and_preprocess_image(x), load_and_preprocess_label(y)))\n",
    "    dataset = dataset.shuffle(buffer_size=len(file_paths))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "# Cr√©ation des datasets d'entra√Ænement et de validation\n",
    "batch_size = 32\n",
    "train_dataset = create_dataset_from_directory(train_dir_rgb, batch_size)\n",
    "train_dataset_nb = create_dataset_from_directory(train_dir_nb, batch_size)\n",
    "val_dataset = create_dataset_from_directory(val_dir_rgb, batch_size)\n",
    "val_dataset_nb = create_dataset_from_directory(val_dir_nb, batch_size)\n",
    "# Fusion des datasets RGB et NB\n",
    "train_dataset = train_dataset.concatenate(train_dataset_nb)\n",
    "val_dataset = val_dataset.concatenate(val_dataset_nb)\n",
    "# Affichage du nombre d'images dans chaque dataset\n",
    "print(f\"[INFO] Nombre d'images d'entra√Ænement : {len(train_dataset)}\")\n",
    "print(f\"[INFO] Nombre d'images de validation : {len(val_dataset)}\")\n",
    "# =======================\n",
    "# üìä Partie 6 : Visualisation des donn√©es\n",
    "# =======================\n",
    "# Fonction pour afficher les images et leurs √©tiquettes\n",
    "def display_images(dataset, num_images=12):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (img, label) in enumerate(dataset.take(num_images)):\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(img[0])\n",
    "        plt.title(f\"Label: {label[0].numpy()}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "# Affichage des images d'entra√Ænement\n",
    "print(\"[DISPLAY] Images d'entra√Ænement\")\n",
    "display_images(train_dataset)\n",
    "# Affichage des images de validation\n",
    "print(\"[DISPLAY] Images de validation\")\n",
    "display_images(val_dataset)\n",
    "# ======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leyenda_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
