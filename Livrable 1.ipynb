{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIVRABLE 1 - Classification binaire (Projet LEYENDA)\n",
    "\n",
    "# Objectif : Distinguer les photos naturelles (couleur ou noir et blanc) des autres types d'images (peintures, textes, dessins, schémas...)\n",
    "\n",
    "CHANGER EN PNG, RESIZE\n",
    "MODELE RGB\n",
    "MODELE NB\n",
    "RECONNAITRE PHOTO PEINTURE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Partie 1 : Initialisation & Vérification GPU\n",
    "# =======================\n",
    "\n",
    "# Importations générales\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "# ✅ Vérification de la disponibilité GPU (TensorFlow GPU Metal)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"[INFO] GPU détecté :\", gpus)\n",
    "else:\n",
    "    print(\"[WARNING] Pas de GPU détecté. Vérifie tensorflow-metal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Partie 2 : Organisation initiale des dossiers\n",
    "# =======================\n",
    "\n",
    "# Chemins des dossiers\n",
    "source_dir = \"./images\"\n",
    "working_dir = \"./images_work\"\n",
    "\n",
    "# Auto-détection des catégories présentes dans source_dir\n",
    "categories = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n",
    "\n",
    "# Création du dossier de travail et copie des images originales\n",
    "os.makedirs(working_dir, exist_ok=True)\n",
    "\n",
    "for category in categories:\n",
    "    src_path = os.path.join(source_dir, category)\n",
    "    dst_path = os.path.join(working_dir, category)\n",
    "\n",
    "    if not os.path.exists(dst_path):\n",
    "        shutil.copytree(src_path, dst_path)\n",
    "        print(f\"[COPIED] Catégorie : {category}\")\n",
    "    else:\n",
    "        print(f\"[ALREADY EXISTS] Catégorie : {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Partie 3 : Tri automatique en Couleur et Noir & Blanc\n",
    "# =======================\n",
    "\n",
    "# Dossier de travail et catégories\n",
    "categories = [\"Painting\", \"Photo\", \"Schematics\", \"Sketch\", \"Text\"]\n",
    "\n",
    "# Fonction pour détecter si une image est en niveau de gris\n",
    "def is_grayscale(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    np_img = np.array(img)\n",
    "    return np.all(np_img[:,:,0] == np_img[:,:,1]) and np.all(np_img[:,:,1] == np_img[:,:,2])\n",
    "\n",
    "# Tri des images selon la couleur\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category)\n",
    "\n",
    "    # Création des sous-dossiers rgb et nb\n",
    "    rgb_path = os.path.join(path, \"rgb\")\n",
    "    nb_path = os.path.join(path, \"nb\")\n",
    "    os.makedirs(rgb_path, exist_ok=True)\n",
    "    os.makedirs(nb_path, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "    for file_name in tqdm(files, desc=f\"[CLASSIFY] {category}\", unit=\"image\"):\n",
    "        file_path = os.path.join(path, file_name)\n",
    "        base_name, ext = os.path.splitext(file_name)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(file_path).convert(\"RGB\")\n",
    "            np_img = np.array(img)\n",
    "\n",
    "            # Vérifier si l'image est en noir et blanc ou couleur\n",
    "            dest_folder = nb_path if is_grayscale(file_path) else rgb_path\n",
    "\n",
    "            # Sauvegarde systématique en PNG\n",
    "            new_filename = base_name + \".png\"\n",
    "            dest_path = os.path.join(dest_folder, new_filename)\n",
    "            img.save(dest_path, \"PNG\")\n",
    "\n",
    "            # Suppression des fichiers originaux non nécessaires\n",
    "            if os.path.abspath(dest_path) != os.path.abspath(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Fichier {file_path} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# Partie 4 : Normalisation de la taille des images \n",
    "# =======================\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category)\n",
    "    resized_path = os.path.join(path, \"resized\", \"rgb\")\n",
    "    os.makedirs(resized_path, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(os.path.join(path, \"rgb\")) if os.path.isfile(os.path.join(path, \"rgb\", f))]\n",
    "    for file_name in tqdm(files, desc=f\"[RESIZE] {category}\", unit=\"image\"):\n",
    "        file_path = os.path.join(path, \"rgb\", file_name)\n",
    "        base_name, ext = os.path.splitext(file_name)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(file_path).convert(\"RGB\")\n",
    "            img_resized = img.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "            new_filename = base_name + \".png\"\n",
    "            dest_path = os.path.join(resized_path, new_filename)\n",
    "            img_resized.save(dest_path, \"PNG\")\n",
    "\n",
    "            # Suppression des fichiers originaux non nécessaires\n",
    "            if os.path.abspath(dest_path) != os.path.abspath(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Fichier {file_path} : {e}\")\n",
    "# Normalisation de la taille des images en noir et blanc\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category)\n",
    "    resized_path = os.path.join(path, \"resized\", \"nb\")\n",
    "    os.makedirs(resized_path, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(os.path.join(path, \"nb\")) if os.path.isfile(os.path.join(path, \"nb\", f))]\n",
    "    for file_name in tqdm(files, desc=f\"[RESIZE] {category}\", unit=\"image\"):\n",
    "        file_path = os.path.join(path, \"nb\", file_name)\n",
    "        base_name, ext = os.path.splitext(file_name)\n",
    "\n",
    "        try:\n",
    "            img = Image.open(file_path).convert(\"RGB\")\n",
    "            img_resized = img.resize((256, 256), Image.Resampling.LANCZOS)\n",
    "            new_filename = base_name + \".png\"\n",
    "            dest_path = os.path.join(resized_path, new_filename)\n",
    "            img_resized.save(dest_path, \"PNG\")\n",
    "\n",
    "            # Suppression des fichiers originaux non nécessaires\n",
    "            if os.path.abspath(dest_path) != os.path.abspath(file_path):\n",
    "                os.remove(file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Fichier {file_path} : {e}\")\n",
    "\n",
    "# Suppression des dossiers temporaires\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category)\n",
    "    shutil.rmtree(os.path.join(path, \"rgb\"), ignore_errors=True)\n",
    "    shutil.rmtree(os.path.join(path, \"nb\"), ignore_errors=True)\n",
    "# =======================\n",
    "print(\"[INFO] Tri et redimensionnement des images terminés.\")\n",
    "# Display des images triées (nombre limité à 12)\n",
    "def display_images_from_folder(folder_path):\n",
    "    images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.png')]\n",
    "    images = images[:12]  # Limiter à 12 images\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, img_path in enumerate(images):\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "# Affichage des images triées\n",
    "for category in categories:\n",
    "    path = os.path.join(working_dir, category, \"resized\", \"rgb\")\n",
    "    print(f\"[DISPLAY] Images de la catégorie : {category}\")\n",
    "    display_images_from_folder(path)\n",
    "# =======================\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "categories = [\"Painting\", \"Photo\", \"Schematics\", \"Sketch\", \"Text\"]\n",
    "img_size = 256\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "working_dir = \"./images_work\" \n",
    "\n",
    "###########################################################################\n",
    "# 1. Préparation des données en classification binaire (Photo vs NonPhoto)  #\n",
    "###########################################################################\n",
    "\n",
    "def prepare_data_binary():\n",
    "    \"\"\"\n",
    "    Organise les images issues des catégories existantes en deux classes :\n",
    "    - \"Photo\" pour la catégorie Photo.\n",
    "    - \"NonPhoto\" pour l’ensemble des autres catégories.\n",
    "    \n",
    "    Les images sont réparties dans des dossiers de train et de test (80%/20%).\n",
    "    \"\"\"\n",
    "    binary_categories = [\"Photo\", \"NonPhoto\"]\n",
    "    train_dir = os.path.join(working_dir, \"train_binary\")\n",
    "    test_dir = os.path.join(working_dir, \"test_binary\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # Création des dossiers de destination pour chaque classe binaire\n",
    "    for cat in binary_categories:\n",
    "        os.makedirs(os.path.join(train_dir, cat), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_dir, cat), exist_ok=True)\n",
    "    \n",
    "    # Parcourir chaque catégorie d'origine\n",
    "    for category in categories:\n",
    "        # Détermine la classe binaire correspondante\n",
    "        new_category = \"Photo\" if category == \"Photo\" else \"NonPhoto\"\n",
    "        \n",
    "        # Chemins des images en niveaux de gris (nb) et en RGB\n",
    "        path_nb = os.path.join(working_dir, category, \"resized\", \"nb\")\n",
    "        path_rgb = os.path.join(working_dir, category, \"resized\", \"rgb\")\n",
    "        \n",
    "        # Si les dossiers n'existent pas, on passe à la catégorie suivante\n",
    "        if not os.path.exists(path_rgb) or not os.path.exists(path_nb):\n",
    "            print(f\"[WARNING] Les dossiers pour la catégorie {category} n'existent pas. Passage.\")\n",
    "            continue\n",
    "        \n",
    "        # Récupération des fichiers\n",
    "        files_rgb = [f for f in os.listdir(path_rgb) if os.path.isfile(os.path.join(path_rgb, f))]\n",
    "        files_nb = [f for f in os.listdir(path_nb) if os.path.isfile(os.path.join(path_nb, f))]\n",
    "        \n",
    "        # Division train / test (80%/20%)\n",
    "        train_files_rgb, test_files_rgb = train_test_split(files_rgb, test_size=0.2, random_state=42)\n",
    "        train_files_nb, test_files_nb = train_test_split(files_nb, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Copier les images RGB et NB dans les dossiers correspondants\n",
    "        for f in tqdm(train_files_rgb, desc=f\"[COPY] Train {category} RGB\", unit=\"image\"):\n",
    "            shutil.copy(os.path.join(path_rgb, f), os.path.join(train_dir, new_category, f))\n",
    "        for f in tqdm(test_files_rgb, desc=f\"[COPY] Test {category} RGB\", unit=\"image\"):\n",
    "            shutil.copy(os.path.join(path_rgb, f), os.path.join(test_dir, new_category, f))\n",
    "        for f in tqdm(train_files_nb, desc=f\"[COPY] Train {category} NB\", unit=\"image\"):\n",
    "            shutil.copy(os.path.join(path_nb, f), os.path.join(train_dir, new_category, f))\n",
    "        for f in tqdm(test_files_nb, desc=f\"[COPY] Test {category} NB\", unit=\"image\"):\n",
    "            shutil.copy(os.path.join(path_nb, f), os.path.join(test_dir, new_category, f))\n",
    "    \n",
    "    # Affichage des informations sur les dossiers créés\n",
    "    print(\"[INFO] Structure des données binaires créée.\")\n",
    "    for cat in binary_categories:\n",
    "        count_train = len(os.listdir(os.path.join(train_dir, cat)))\n",
    "        count_test = len(os.listdir(os.path.join(test_dir, cat)))\n",
    "        print(f\"[INFO] {cat} - Train: {count_train}, Test: {count_test}\")\n",
    "    \n",
    "    return train_dir, test_dir\n",
    "\n",
    "###################################\n",
    "# 2. Chargement des données       #\n",
    "###################################\n",
    "\n",
    "def load_data_binary(train_dir, test_dir):\n",
    "    \"\"\"\n",
    "    Charge les données en appliquant une normalisation (rescale=1./255).\n",
    "    Renvoie les générateurs pour l'entraînement et le test.\n",
    "    \"\"\"\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, test_generator\n",
    "\n",
    "###################################\n",
    "# 3. Construction du modèle       #\n",
    "###################################\n",
    "\n",
    "def build_model_binary():\n",
    "    \"\"\"\n",
    "    Construit un modèle CNN pour la classification binaire (Photo vs NonPhoto).\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "###################################\n",
    "# 4. Entraînement du modèle       #\n",
    "###################################\n",
    "\n",
    "def train_model_binary(model, train_generator, test_generator):\n",
    "    \"\"\"\n",
    "    Entraîne le modèle en utilisant l'arrêt précoce et la sauvegarde du meilleur modèle.\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_binary.h5', save_best_only=True, monitor='val_loss')\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=test_generator,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "###################################\n",
    "# 5. Évaluation du modèle         #\n",
    "###################################\n",
    "\n",
    "def evaluate_model_binary(model, test_generator):\n",
    "    \"\"\"\n",
    "    Évalue le modèle sur les données de test, affiche le rapport de classification\n",
    "    et trace la matrice de confusion.\n",
    "    \"\"\"\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "    print(f\"[INFO] Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred_class = (y_pred > 0.5).astype(\"int32\")\n",
    "    \n",
    "    print(\"[INFO] Rapport de classification:\")\n",
    "    print(classification_report(test_generator.classes, y_pred_class))\n",
    "    \n",
    "    cm = confusion_matrix(test_generator.classes, y_pred_class)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "###################################\n",
    "# 6. Exemple de prédiction unique #\n",
    "###################################\n",
    "\n",
    "def detect_photo(model, image_path):\n",
    "    \"\"\"\n",
    "    Charge une image, la prétraite, et effectue la prédiction.\n",
    "    Affiche ensuite si l'image est une Photo ou non.\n",
    "    \"\"\"\n",
    "    img = load_img(image_path, target_size=(img_size, img_size))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    \n",
    "    pred = model.predict(img_array)\n",
    "    if pred[0][0] > 0.5:\n",
    "        print(\"L'image est une Photo.\")\n",
    "    else:\n",
    "        print(\"L'image n'est pas une Photo.\")\n",
    "\n",
    "###################################\n",
    "# 7. Fonction principale          #\n",
    "###################################\n",
    "\n",
    "def main():\n",
    "    # Préparation et chargement des données en mode binaire\n",
    "    train_dir, test_dir = prepare_data_binary()\n",
    "    train_generator, test_generator = load_data_binary(train_dir, test_dir)\n",
    "    \n",
    "    # Construction et entraînement du modèle\n",
    "    model = build_model_binary()\n",
    "    history = train_model_binary(model, train_generator, test_generator)\n",
    "    \n",
    "    # Évaluation du modèle sur les données de test\n",
    "    evaluate_model_binary(model, test_generator)\n",
    "    \n",
    "    # Exemple de détection sur une image individuelle (modifiez le chemin)\n",
    "    image_path = \"./dd/boat.png\"\n",
    "    detect_photo(model, image_path)\n",
    "\n",
    "    # Affichage de l'historique d'entraînement\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # Affichage de la courbe de perte\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()   \n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leyenda_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
